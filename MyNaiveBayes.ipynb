{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "class MyNaiveBayes:\n",
        "  def __init__(self):\n",
        "    self.class_probs = defaultdict(int)      #P(label)\n",
        "    self.feature_probs = defaultdict(dict)   #P(xi/label)\n",
        "    self.classes = set()                     #set of all labels\n",
        "    self.vocab = set()                       #set of all words\n",
        "\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    total_samples = len(Y)\n",
        "    class_count = defaultdict(int)\n",
        "    feature_count = defaultdict(lambda: defaultdict(int))\n",
        "    feature_totals = defaultdict(int)\n",
        "\n",
        "    for xi, label in zip(X,Y):\n",
        "      self.classes.add(label)\n",
        "      class_count[label] += 1\n",
        "      for feature in xi:\n",
        "        feature_count[label][feature] += 1\n",
        "        feature_totals[label] += 1\n",
        "        self.vocab.add(feature)\n",
        "\n",
        "    #calculate prior probabilities\n",
        "    for label in self.classes:\n",
        "      self.class_probs[label] = class_count[label] / total_samples\n",
        "\n",
        "    #calculate posterior probabilities P(xi/label) with laplace smoothing\n",
        "    for label in self.classes:\n",
        "      for word in self.vocab:\n",
        "        self.feature_probs[word][label] = (feature_count[label][word] + 1) / (feature_totals[label] + len(self.vocab))\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = []\n",
        "    for xi in X:\n",
        "      result_class = None\n",
        "      max_log_prob = float('-inf')\n",
        "      for label in self.classes:\n",
        "        score = math.log(self.class_probs[label])\n",
        "        for word in xi:\n",
        "          score += math.log(self.feature_probs.get(word, {}).get(label, 1/(len(self.vocab) + 1)))\n",
        "        if score > max_log_prob:\n",
        "          max_log_prob = score\n",
        "          result_class = label\n",
        "      predictions.append(result_class)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "aA94MNuJXW4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [\n",
        "    ['chinese', 'beijing', 'chinese'],\n",
        "    ['chinese', 'chinese', 'shanghai'],\n",
        "    ['chinese', 'macao'],\n",
        "    ['tokyo', 'japan', 'chinese']\n",
        "]\n",
        "y_train = ['yes', 'yes', 'yes', 'no']\n",
        "\n",
        "X_test = [['chinese', 'tokyo', 'japan']]\n",
        "\n",
        "model = MyNaiveBayes()\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"Prediction:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsJC7aATdkgk",
        "outputId": "96793018-ece2-44ff-bd81-0971106a015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ['no']\n"
          ]
        }
      ]
    }
  ]
}